# -*- coding: utf-8 -*-
"""Project_1 Supervised Learning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EiaXHwUD0j65xja2SfIHnxniIKNTpfA6

# **Predicting Heart disease using machine learning**


---
We are going to take the following approach
1. Problem definition
2. Data
3. Evaluation
4. Features
5. Modelling
6. Experimentation

### 1. Problem definition
In a statement,
Given clinical parameters about a patient ,can we predict whether or not they have heart disease

### 2. Data
This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to
this date. The "goal" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4. 

### 3. Evaluation
If we can reach 95% accuracy at predicting whether or not a patient has heart disease during the proof of concept, we'll pursue the project.

### 4. Features
Getting different information about each of the features in your data

Create a data dictionary



1. age - age in years
2. sex - (1 = male; 0 = female)
3. cp - chest pain type:
  *  0: Typical angina: chest pain related decrease blood supply to the heart
   * 1: Atypical angina: chest pain not related to heart
   * 2: Non-anginal pain: typically esophageal spasms (non heart related)
   * 3: Asymptomatic: chest pain not showing signs of disease

4. trestbps - resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern
5. chol - serum cholestoral in mg/dl 
serum = LDL + HDL + .2  *triglyceridesabove 200 is cause for concern

6. fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) '>126' mg/dL signals diabetes

7. restecg - resting electrocardiographic results
    * 0: Nothing to note
    * 1: ST-T Wave abnormality can range from mild symptoms to severe problems signals non-normal heart beat
    * 2: Possible or definite left ventricular hypertrophy Enlarged heart's main pumping chamber

8. thalach - maximum heart rate achieved
9. exang - exercise induced angina (1 = yes; 0 = no)
10. oldpeak - ST depression induced by exercise relative to rest looks at stress of heart during excercise unhealthy heart will stress more
11. slope - the slope of the peak exercise ST segment
    * 0: Upsloping: better heart rate with excercise (uncommon)
    * 1: Flatsloping: minimal change (typical healthy heart)
    * 2: Downslopins: signs of unhealthy heart

12. ca - number of major vessels (0-3) colored by flourosopy
    * colored vessel means the doctor can see the blood passing through
    * the more blood movement the better (no clots)

13. thal - thalium stress result

    * 1,3: normal
    * 6: fixed defect: used to be defect but ok now
    * 7: reversable defect: no proper blood movement when excercising

14. target - have disease or not (1=yes, 0=no) (= the predicted attribute)

## Preparing the tools
*** We are going to use pandas,matplotlib,Numpy  for data analysis and manipulation ***
"""

# Commented out IPython magic to ensure Python compatibility.
# Import all the tools we need

# Regular EDA (exploratory data analysis) and plotting libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# We want our plots to appear inside the notebook
# %matplotlib inline 

# Modles from Scikit-Learn
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# Model evaluations
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.model_selection import RandomizedSearchCV,GridSearchCV
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.metrics import precision_score,recall_score,f1_score
from sklearn.metrics import plot_roc_curve

# Make all figsizes 10,6 10 inches wide ,6 inches height with rc param
plt.rcParams["figure.figsize"] = (10,6)

"""#Load data"""

df = pd.read_csv("/content/drive/MyDrive/machine_learning/data/heart-disease.csv")
df.shape

df.dtypes

"""## Data exploration (Exploratory data analysis or EDA)

The goal here is to find out more about the data and become a su5.bject matter export on the dataset you are working on

1. What questions are you trying to solve
2. What kind of data do we have and how do we treat different types
3. What's missing from the data and how do you deal with it
4. Where are the outliers and why should you care about them
5. How can you add,change or remove features to get more out of your data

"""

df.head()

df.tail()

# Lets find how many of each class we have
df["target"].value_counts()

df["target"].value_counts().plot(kind="bar",color=["salmon","lightblue"]);

df.info()

# Are there any missing values
df.isna().sum()

df.describe()

"""## Heart disease Frequency accoding to sex

"""

df.sex.value_counts()

# Compare target column with sex column
pd.crosstab(df.target,df.sex)

# Create a plot of crosstab

pd.crosstab(df["target"],df["sex"]).plot(kind="bar",
                                         figsize=(10,6),
                                         color=["salmon","lightblue"])

plt.title("Heart disease frequency for Sex")
plt.xlabel("0 = No disease,1 = Disease")
plt.ylabel("Amount of people")
plt.legend(["Female","Male"])
plt.xticks(rotation=0);

df["thalach"].value_counts()

"""##  **Age vs Max Heart Rate for Heart Disease**"""

# Create another figure
plt.figure(figsize=(10,6))

# Scatter with positive examples
plt.scatter(df.age[df.target==1],
            df.thalach[df.target==1],
            color="salmon");

# Scattee with negative examples
plt.scatter(df.age[df.target==0],
            df.thalach[df.target==0],
            color="lightblue")

# Add some helpfull info
plt.title("Heart Disease in function of age and max heart rate")
plt.xlabel("Age"),
plt.ylabel("Max Heart Rate")
plt.legend(["Disease","No Disease"]);

# Check the distribution of the age column with a histogram
df.age.plot.hist();

"""# **Heart Disease Frequency for chest pain type**

3. cp - chest pain type:

    * 0: Typical angina: chest pain related decrease blood supply to the heart
    * 1: Atypical angina: chest pain not related to heart
    * 2: Non-anginal pain: typically esophageal spasms (non heart related)
    * 3: Asymptomatic: chest pain not showing signs of disease


"""

pd.crosstab(df.cp,df.target)

# Make the crosstab between the chest pain type and target more visual
pd.crosstab(df.cp,df.target).plot(kind="bar",
                                  color=["salmon","lightblue"]);

# Add some communication
plt.title("Heart Disease Frequency Per Chest Pain Type")
plt.xlabel("Chest Pain Type")
plt.ylabel("Amount")
plt.legend(["No Disease","Disease"])
plt.xticks(rotation=0);

"""## **Make a correlation matrix**"""

df.corr()

# Lets make the correlation matrix more visual with sns heatmap
corr_matrix = df.corr()

fig,ax = plt.subplots(figsize=(15,10))
ax = sns.heatmap(corr_matrix,
                 annot=True,
                 linewidths=0.5,
                 fmt=".2f",
                 cmap='YlGnBu');

"""# 5. Modelling"""

# Split data into X and y
X = df.drop("target",axis=1)

y = df["target"]

# Import random seed
np.random.seed(42)

# Split data into train and test sets
X_train , X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

X_train

y_train

"""### - **Now we have our data split into train and test sets so its time to build a machine learning model.**
### - **We will train it (find patterns) on the training set.**
### - **And we will test is (use the patters) on the test set**

---

### We are goint to try 3 different machine learning models:
1. Logistic Regression
2. K-Nearest Neighbours Classifier
3. Random Forest Classifier
"""

# Put models in a dictionary
models = {"Logistic Regression": LogisticRegression(),
          "KNN": KNeighborsClassifier(),
          "Random Forest": RandomForestClassifier()}

# Create a function to fit and score models
def fit_and_score(models, X_train, X_test, y_train, y_test):
    """
    Fits and evaluates given machine learning models.
    models : a dict of differetn Scikit-Learn machine learning models
    X_train : training data (no labels)
    X_test : testing data (no labels)
    y_train : training labels
    y_test : test labels
    """
    # Set random seed
    np.random.seed(42)
    # Make a dictionary to keep model scores
    model_scores = {}
    # Loop through models
    for name, model in models.items():
        # Fit the model to the data
        model.fit(X_train, y_train)
        # Evaluate the model and append its score to model_scores
        model_scores[name] = model.score(X_test, y_test)
    return model_scores

model_scores = fit_and_score(models=models,
                             X_train=X_train,
                             X_test=X_test,
                             y_train=y_train,
                             y_test=y_test)

model_scores

# Model Comparison
model_compare = pd.DataFrame(model_scores,index=["Accuracy"])

model_compare.T.plot.bar(color="salmon");

"""Now we have a baseline model
- What should we do next?


---


 Lets look at the following:
 * Hyperparameter tuning
 * Feature importance
 * Confusion Matrix
 * Cross-validation
 * Precision
 * Recall
 * f1 score
 * Classification report
 * ROC curve
 * Area under the curve (AUC)

# Hyperparameter tuning
"""

# Lets tune KNN

train_scores = []
test_scores = []

# Create a list of different values for n_neighbours
neighbours = range(1,21)

# Set up KNN instance
knn = KNeighborsClassifier()

# Loop throudh different n_neighbours
for i in neighbours:
  knn.set_params(n_neighbors=i)

  # Fit the algorithm
  knn.fit(X_train,y_train)
  # Update the training scores list
  train_scores.append(knn.score(X_train,y_train))
  # Update the test scoes list
  test_scores.append(knn.score(X_test,y_test))

train_scores

test_scores

plt.plot(neighbours,train_scores,label="Train score")
plt.plot(neighbours,test_scores,label="Test score")

plt.xticks(np.arange(1,21,1))

plt.xlabel("Number of neighbors")
plt.ylabel("Model score")
plt.legend()

print(f'Maximum KNN score on the test data: {max(test_scores) *100:.2f}%')

"""# Hyper parameter tuning with RandomizedSearchCV

---
We are going to tune:
* Logistic Regression
* RandomForestClassifier

Using RandomizedSearchCV

"""

# Create a hyperparameter grid for LogisticRegression
log_reg_grid = {"C":np.logspace(-4,4,20),
                "solver":["liblinear"]}

# Create a hyperparameter grid for RandomForestClassifier
rf_grid = {"n_estimators": np.arange(10,1000,50),
           "max_depth":[None,3,5,10],
           "min_samples_split":np.arange(2,20,2),
           "min_samples_leaf":np.arange(1,20,2)}

"""**Now we have hyperparameter gris setup for each of our models,lets tune them with RandomizedSearchCV**"""

# Tune LogisticRegression

np.random.seed(42)

# Setup random hyperparameter search for LogisticRegression
rs_log_reg = RandomizedSearchCV(LogisticRegression(),
                                param_distributions=log_reg_grid,
                                cv=5,
                                n_iter=20,
                                verbose=True)

# Fit random Hyperparameter search model for LogisticRegression
rs_log_reg.fit(X_train,y_train)

rs_log_reg.best_params_

rs_log_reg.score(X_test,y_test)

"""**Now we have tuned Logistic Regression() lets do the same for RandomForestClassifier()**"""

# Set up random seed
np.random.seed(42)

# Set up random hyperparameter search for RandomForestClassifier
rs_rf = RandomizedSearchCV(RandomForestClassifier(),
                           param_distributions=rf_grid,
                           cv=5,
                           n_iter=20,
                           verbose=True)

# Fit random hyperparameter search model for RandomForestClassifier
rs_rf.fit(X_train,y_train)

rs_rf.best_params_

# Evaluate the randomized search RandomForestClassifier model
rs_rf.score(X_test,y_test)

model_scores

"""3 ways to tune hyperparametes

1. By hand
2. RandomizedSearchCV
3. GridSearchCV

# **Hyperparameter Tuning with GridSearchCV**


---

*since our LogisticRegression model provides the best model so far we will try and improve again using GridSearchCV*
"""

# Simple Hyperparameter for LogisticRegression
log_reg_grid = {"C":np.logspace(-4,4,20),
                "solver":["liblinear"]}

# # Different Hyperparameters for our LogisticRegression model
# log_reg_grid = {"C":np.logspace(-4,4,30),
#                 "solver":["liblinear","sag","saga","newton-cg","lbfgs"],
#                 "max_iter":[100,1000,2500,5000],
#                 "penalty":["l1","l2","none","elasticnet"]}

# Set up grid Hyperparameter search for LogisticRegression
gs_log_reg = GridSearchCV(LogisticRegression(),
                          param_grid=log_reg_grid,
                          cv=5,
                          verbose=True)

# Fit grid hyperparameter search model
gs_log_reg.fit(X_train,y_train)

gs_log_reg.best_params_

gs_log_reg.score(X_train,y_train)

"""# Evaluating our tuned machine learning classifier,beyond accuracy

* **ROC curve and AUC score**
* **confusion matrix**
* **Classification report**
* **Precision**
* **Recall**
* **f1 score**

and it would be great if cross-validatiopn was used where possible


---
To make comparisons and evaluate our trained model first we need to make predictions.

"""

# Make predictions with tuned model
y_preds = gs_log_reg.predict(X_test)
y_preds

# We have already imported the roc curve from sklearn.metrics module

# Plot the ROC curve and calculate AUC metric
plot_roc_curve(gs_log_reg,X_test,y_test);

import seaborn as sns

sns.set(font_scale=1.5)# Increases font size

def plot_conf(y_test,y_preds):
  """
  Plots a confusion matrix using Seaborn's Heatmap().
  """
  fig,ax = plt.subplots(figsize=(5,5))
  ax = sns.heatmap(confusion_matrix(y_test,y_preds),
                   annot=True,
                   cbar=False)
  plt.xlabel("Predicted label")
  plt.ylabel("True label")

plot_conf(y_test,y_preds)

"""**Now we have a ROC curve an AUC metric and a confusion matrix lets get a classification report as well as cross-validated precision recall and f1 score**"""

print(classification_report(y_test,y_preds))

"""# Calculate evaluation metrics using cross-validation

We are going to calculate accuracy,precision,recall and f1 score on our model using cross-validation and to do so we will be using cross_val_score
"""

# Check best hyperparameters
gs_log_reg.best_params_

# Create a new classifier with best parameters

clf = LogisticRegression(C=0.23357214690901212,
                         solver="liblinear")

# Cross validated Accuracy

cv_acc = cross_val_score(clf,
                         X,
                         y,
                         cv=5,
                         scoring="accuracy")
cv_acc

cv_acc = round(np.mean(cv_acc),2)
cv_acc

# Cross validated precision
cv_precision = cross_val_score(clf,
                               X,
                               y,
                               cv=5,
                               scoring="precision")
cv_precision

cv_precision = round(np.mean(cv_precision),2)
cv_precision

# Cross validated recall
cv_recall = cross_val_score(clf,
                            X,
                            y,
                            cv=5,
                            scoring="recall")
cv_recall

cv_recall = round(np.mean(cv_recall),2)
cv_recall

# F1 score
cv_f1 = cross_val_score(clf,
                        X,
                        y,
                        cv=5,
                        scoring="f1")
cv_f1

cv_f1 = round(np.mean(cv_f1),2)
cv_f1

cross_validated_scores = pd.DataFrame({"Precision":cv_precision,
                         "Accuracy":cv_acc,
                         "Recall":cv_recall,
                         "F1":cv_f1},index=[0])

cross_validated_scores

cross_validated_scores.T.plot.bar(title="Cross validated scores",
                                  legend=False)
plt.xticks(rotation=0);

"""# Finding the most important Features

**Feature importance is another as asking ,which features contributed the most to the outcome of the model and how did they contribute**


---
Finding Feature importance is different for each machine learning model.One way to tind feature importance is to search for (MODEL NAME) feature importance


"""

# Fit an instance of LogisticRegression
gs_log_reg.best_params_

clf = LogisticRegression(C=0.23357214690901212,
                         solver="liblinear")
clf.fit(X_train,y_train);

# Check coef_
clf.coef_

# Match coef_ of features to columns
feature_dict = dict(zip(df.columns,list(clf.coef_[0])))
feature_dict

# Visualize feature importance
feature_df = pd.DataFrame(feature_dict,index=[0])

feature_df.T.plot.bar(title="Feature importance",
                      legend=False,
                      color='salmon');

pd.crosstab(df.sex,df.target)

72/24

113/93

pd.crosstab(df.slope,df.target)

!pip install catboost

# Trying out the Cat boost model with gridsearchcvgr
from catboost import CatBoostRegressor,CatBoostClassifier,Pool

cat_model = CatBoostClassifier(verbose=True)

cat_model.fit(X_train,y_train)

y_preds_cat = cat_model.predict(X_test)
cat_model.score(X_test,y_test)

plot_conf(y_test,y_preds_cat)

cat_model.get_feature_importance()

# Match coef_ of features to columns
feature_dict = dict(zip(df.columns,list(cat_model.get_feature_importance())))
feature_dict

# Visualize feature importance
feature_df = pd.DataFrame(feature_dict,index=[0])

feature_df.T.plot.bar(title="Feature importance",
                      legend=False,
                      color='salmon');